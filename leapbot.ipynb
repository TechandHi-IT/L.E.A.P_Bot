{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Leinad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "labels = []\n",
    "docs_x = []\n",
    "docs_y = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "\tfor pattern in intent[\"patterns\"]:\n",
    "\t\twrds = nltk.word_tokenize(pattern)\n",
    "\t\twords.extend(wrds)\n",
    "\t\tdocs_x.append(wrds)\n",
    "\t\tdocs_y.append(intent[\"tag\"])\n",
    "\n",
    "\tif intent[\"tag\"] not in labels:\n",
    "\t\tlabels.append(intent[\"tag\"])\n",
    "\n",
    "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "labels = sorted(labels)\n",
    "\n",
    "\n",
    "training = []\n",
    "output = []\n",
    "\n",
    "out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "for x, doc in enumerate(docs_x):\n",
    "\tbag = []\n",
    "\n",
    "\twrds = [stemmer.stem(w) for w in doc]\n",
    "\n",
    "\tfor w in words:\n",
    "\t\tif w in wrds:\n",
    "\t\t\tbag.append(1)\n",
    "\t\telse:\n",
    "\t\t\tbag.append(0)\n",
    "\toutput_row = out_empty[:]\n",
    "\toutput_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "\ttraining.append(bag)\n",
    "\toutput.append(output_row)\n",
    "\n",
    "training = numpy.array(training)\n",
    "output = numpy.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4999  | time: 0.018s\n",
      "| Adam | epoch: 1000 | loss: 0.00000 - acc: 1.0000 -- iter: 32/34\n",
      "Training Step: 5000  | time: 0.025s\n",
      "| Adam | epoch: 1000 | loss: 0.00000 - acc: 1.0000 -- iter: 34/34\n",
      "--\n",
      "INFO:tensorflow:c:\\Users\\Leinad\\Documents\\Tech_Villain\\TechandHi\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\tmodel.load(\"model.tflearn\")\n",
    "except:\n",
    "\tmodel = tflearn.DNN(net)\n",
    "\tmodel.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "\tmodel.save(\"model.tflearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s,words):\n",
    "\tbag = [0 for _ in range(len(words))]\n",
    "\n",
    "\n",
    "\ts_words = nltk.word_tokenize(s)\n",
    "\ts_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "\tfor se in s_words:\n",
    "\t\tfor i, w in enumerate(words):\n",
    "\t\t\tif w == se:\n",
    "\t\t\t\tbag[i] = 1\n",
    "\n",
    "\treturn numpy.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "\tprint(\"Start Talking with the bot(type quit to stop!\")\n",
    "\twhile True:\n",
    "\t\tinp = input(\"You: \")\n",
    "\t\tif inp.lower() == \"quit\":\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tresults = model.predict([bag_of_words(inp,words)])[0]\n",
    "\t\tresults_index = numpy.argmax(results)\n",
    "\t\ttag = labels[results_index]\n",
    "\n",
    "\t\tif results[results_index] > 0.5:\n",
    "\t\t\tfor tg in data[\"intents\"]:\n",
    "\t\t\t\tif tg['tag'] == tag:\n",
    "\t\t\t\t\tresponses = tg['responses']\t\n",
    "\t\t\tprint(random.choice(responses))\n",
    "\t\t\tprint(\"\\n\")\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Sorry you feel this way\\nMind me recommending a place that can provide you with the care you nend?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Talking with the bot(type quit to stop!\n",
      "I'm really sorry to hear that you're feeling this way. Remember, you're stronger than you think. Tough times don't last forever, and you have the power to overcome them. Believe in yourself and take things one step at a time.\n",
      "It's completely normal to feel overwhelmed at times. Just remember, you have an incredible strength within you. You've faced challenges before and come out on top. You can do it again.\n",
      "I'm here to support you through this. You're not alone. Sometimes, the darkest moments can lead to the most beautiful transformations. Keep moving forward, and you'll find your light.\n",
      "\n",
      "\n",
      "Sorry you feel this way\n",
      "Mind me recommending a place that can provide you with the care you nend?\n",
      "Take care. If you ever need assistance or someone to talk to, please feel free to reach out. You're not alone in this.\n",
      "\n",
      "\n",
      "Glad I could help and thank you for trusting me to open up as per the privacy regulations your data is secured\n",
      "but I'd still like to recommend people that can give you the care you need\n",
      "\n",
      "\n",
      "Human Development Initiative(HDI) - Call: 08080551376, link: hdinigeria.org\n",
      "Surpin Helpline Nigeria - Call: 08000787746, link: surpinng.com\n",
      "Mentally Aware Nigeria Initiative - Call: (809) 111-6264, link: mentallyaware.org\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
